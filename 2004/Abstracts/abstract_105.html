<!doctype html public "-//w3c//dtd html 4.0 transitional//en>"
<html>
<head>
   <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
   <title> Cluster 2004 Abstract: Analysis of microbenchmarks for performance tuning of clusters </title>
</head>
<center>
<h2>Analysis of microbenchmarks for performance tuning of clusters</h2>
</center>
<p> 
<center>
<h3>Matthew Sottile, et. al</h3>
</center>
<hr>
<blockquote>
Microbenchmarks, i.e. very small computional kernels, have become   commonly used for quantitative measures of node performance in clusters.  For example, a commonly used benchmark times the amount of time required   to perform a constant quantum of work.  Unfortunately, this benchmark is   one of many that violate well known rules from sampling theory, leading to   erroneous, contradictory or misleading results.  At a minimum, these types of   benchmarks can not be used to identify time-based activities that may   interfere with and hence limit application performance.  In this paper, we   discuss why the 'constant quantum of work' benchmark provides data that is   of limited use for analysis;  and we show code for, discuss, and analyze   results from a microbenchmark which follows good rules of sampling   hygiene, and hence provides useful data for analysis.  PHIL THIS IS A PLACEHOLDER 
</blockquote>
<hr>
<font size=-1><a href="../program.html">Back to Program</a></font>
</body>
</<html>
